{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import time\n",
    "import datetime \n",
    "from datetime import timedelta\n",
    "\n",
    "from prophet import Prophet\n",
    "from influxdb_client import InfluxDBClient\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-12 19:15:44.208909\n",
      "<class 'datetime.datetime'>\n",
      "<class 'str'>\n",
      "2022-09-12T18:45\n",
      "2022-09-12T19:15\n",
      "2022-09-12 18:45:00\n",
      "<class 'datetime.datetime'>\n",
      "2022-09-12 19:15:00\n"
     ]
    }
   ],
   "source": [
    "INFLUXDB_HOST = os.getenv(\"INFLUX_HOST\", \"10.147.17.17\")\n",
    "INFLUXDB_PORT = os.getenv(\"INFLUXDB_PORT\", \"8086\")\n",
    "INFLUXDB_ORG = os.getenv(\"INFLUXDB_ORG\", \"lomo\")\n",
    "INFLUXDB_BUCKET = os.getenv(\"INFLUXDB_BUCKET\", \"lomo\")\n",
    "INFLUXDB_TOKEN = os.getenv(\"INFLUX_TOKEN\", \"adminadminadmin\")\n",
    "\n",
    "client = InfluxDBClient(url=\"http://\"+INFLUXDB_HOST+\":\"+INFLUXDB_PORT, token=INFLUXDB_TOKEN, org=INFLUXDB_ORG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_to_dataframe(result):\n",
    "    raw = []\n",
    "    for table in result:\n",
    "        for record in table.records:\n",
    "            raw.append((record.get_value(), record.get_time()))\n",
    "    return pd.DataFrame(raw, columns=['y','ds'], index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = 'temp'\n",
    "device_id = '631b3625425b4db69832bdf9'\n",
    "\n",
    "interval = 30\n",
    "start_times =['2022-09-09T15:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 11:33:10,596 - cmdstanpy - DEBUG - cmd: where.exe tbb.dll\n",
      "cwd: None\n",
      "2022-09-13 11:33:10,687 - cmdstanpy - DEBUG - TBB already found in load path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-09T15:00\n",
      "2022-09-09T15:30\n",
      "Check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 11:33:10,693 - prophet - INFO - Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "2022-09-13 11:33:10,694 - prophet - INFO - Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "2022-09-13 11:33:10,694 - prophet - INFO - Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "2022-09-13 11:33:10,704 - prophet - INFO - n_changepoints greater than number of observations. Using 7.\n",
      "2022-09-13 11:33:10,707 - cmdstanpy - DEBUG - input tempfile: C:\\Users\\barba\\AppData\\Local\\Temp\\tmpz3lmno2u\\o79y0_9o.json\n",
      "2022-09-13 11:33:10,709 - cmdstanpy - DEBUG - input tempfile: C:\\Users\\barba\\AppData\\Local\\Temp\\tmpz3lmno2u\\9bs6wpqi.json\n",
      "2022-09-13 11:33:10,712 - cmdstanpy - DEBUG - idx 0\n",
      "2022-09-13 11:33:10,713 - cmdstanpy - DEBUG - running CmdStan, num_threads: None\n",
      "2022-09-13 11:33:10,713 - cmdstanpy - DEBUG - CmdStan args: ['C:\\\\Python39\\\\Lib\\\\site-packages\\\\prophet\\\\stan_model\\\\prophet_model.bin', 'random', 'seed=14854', 'data', 'file=C:\\\\Users\\\\barba\\\\AppData\\\\Local\\\\Temp\\\\tmpz3lmno2u\\\\o79y0_9o.json', 'init=C:\\\\Users\\\\barba\\\\AppData\\\\Local\\\\Temp\\\\tmpz3lmno2u\\\\9bs6wpqi.json', 'output', 'file=C:\\\\Users\\\\barba\\\\AppData\\\\Local\\\\Temp\\\\tmpk8hxtaca\\\\prophet_model-20220913113310.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "11:33:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "2022-09-13 11:33:10,714 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:33:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2022-09-13 11:33:10,775 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       y                         ds\n",
      "10  30.2 2022-09-09 15:23:30.065008\n",
      "11  30.2 2022-09-09 15:25:43.457965\n",
      "12  29.9 2022-09-09 15:27:56.796616\n",
      "9\n",
      "0.01713366585086191\n",
      "[0.01713366585086191]\n",
      "                   ds     y       yhat\n",
      "0 2022-09-09 15:23:00  30.2  30.208744\n",
      "1 2022-09-09 15:25:00  30.2  30.000602\n",
      "2 2022-09-09 15:27:00  29.9  29.792460\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mse_array = []\n",
    "forecasted_array = []\n",
    "\n",
    "for start_time in start_times:\n",
    "    stop_time = datetime.datetime.strptime(start_time, \"%Y-%m-%dT%H:%M\")\n",
    "    stop_time = (stop_time + datetime.timedelta(minutes=interval)).strftime(\"%Y-%m-%dT%H:%M\")\n",
    "\n",
    "    print(start_time)\n",
    "    print(stop_time)\n",
    "    \n",
    "    query = 'from(bucket: \"lomo\")' \\\n",
    "            ' |> range(start:' +  start_time+\":00Z\" + ', stop:' + stop_time+\":00Z\" + ')'\\\n",
    "            ' |> filter(fn: (r) => r[\"_measurement\"] == \"devices\")' \\\n",
    "            ' |> filter(fn: (r) => r[\"_field\"] == \"' + field + '\")' \\\n",
    "            ' |> filter(fn: (r) => r[\"id\"] == \"' + device_id+'\")'\n",
    "    result = client.query_api().query(org=INFLUXDB_ORG, query=query)\n",
    "    print(\"Check\")\n",
    "    #print(result)\n",
    "    # Convert the results to dataframe\n",
    "    df = result_to_dataframe(result)\n",
    "    df['ds'] = df['ds'].dt.tz_localize(None)\n",
    "    train, test = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "    m = Prophet(changepoint_prior_scale=0.01).fit(train)\n",
    "    print(test.head())\n",
    "\n",
    "    test_interval = int((test.iloc[-1]['ds'].timestamp() - test.iloc[0]['ds'].timestamp()) / 60)\n",
    "    test_interval = test_interval + 5\n",
    "    print(test_interval)\n",
    "\n",
    "    future = m.make_future_dataframe(periods=test_interval, freq= DateOffset(minutes=1))\n",
    "    forecast = m.predict(future)\n",
    "\n",
    "    forecast['ds'] = forecast.ds.dt.floor('min')\n",
    "    test['ds'] = test.ds.dt.floor('min')\n",
    "    metric = test.set_index('ds')[['y']].join(forecast.set_index('ds').yhat).reset_index()\n",
    "    mse = mean_squared_error(metric['y'], metric['yhat'])\n",
    "    print(mse)\n",
    "\n",
    "    mse_array.append(mse) #trovare il modo di salvare tutti i dati\n",
    "    forecasted_array.append(metric)\n",
    "print(mse_array)\n",
    "print(metric)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
